"""
Script d'initialisation : Upload du mod√®le Wakee vers HuggingFace Hub
√Ä ex√©cuter UNE SEULE FOIS pour cr√©er le repo model
"""

from huggingface_hub import HfApi, create_repo, login
import json
import os
from pathlib import Path

# ============================================================================
# CONFIGURATION - √Ä MODIFIER SELON TON SETUP
# ============================================================================

HF_USERNAME = "Terorra"  # üëà TON username HuggingFace
MODEL_NAME = "wakee-reloaded"
REPO_ID = f"{HF_USERNAME}/{MODEL_NAME}"

# Chemins vers tes fichiers (depuis wakee_reloaded/)
ONNX_MODEL_PATH = "../00_wakee/model_legacy/daisee_model.onnx"  # üëà Ton ONNX existant

# ============================================================================
# 1. LOGIN HUGGINGFACE
# ============================================================================

print("üîê Connexion √† HuggingFace...")
print("\n‚ö†Ô∏è  Tu vas avoir besoin d'un token HuggingFace !")
print("üëâ Va sur : https://huggingface.co/settings/tokens")
print("üëâ Cr√©e un token avec permissions 'write'")
print("üëâ Copie-le et colle-le ci-dessous\n")

# Option 1 : Login interactif (recommand√© premi√®re fois)
try:
    login()
    print("‚úÖ Connexion r√©ussie !\n")
except Exception as e:
    print(f"‚ùå Erreur de connexion : {e}")
    print("\nüí° Alternative : d√©finis la variable d'environnement")
    print("   export HF_TOKEN='ton_token_ici'")
    exit(1)

# Option 2 : Si tu as d√©j√† le token en variable d'environnement
# from huggingface_hub import login
# login(token=os.getenv("HF_TOKEN"))

api = HfApi()

# ============================================================================
# 2. CR√âER LE REPO MODEL
# ============================================================================

print(f"üì¶ Cr√©ation du repo : {REPO_ID}")

# try:
#     create_repo(
#         repo_id=REPO_ID,
#         repo_type="model",
#         private=False,  # Public pour que l'API puisse y acc√©der
#         exist_ok=True   # Ne plante pas si existe d√©j√†
#     )
#     print(f"‚úÖ Repo cr√©√© : https://huggingface.co/{REPO_ID}\n")
# except Exception as e:
#     print(f"‚ö†Ô∏è  Repo existe d√©j√† ou erreur : {e}\n")

# ============================================================================
# 3. CR√âER LE CONFIG.JSON
# ============================================================================

print("üìù Cr√©ation du fichier config.json...")

config = {
    "model_type": "efficientnet-b4",
    "architecture": "EfficientNet B4 fine-tuned on DAiSEE",
    "task": "multi-label-regression",
    "num_labels": 4,
    "label_names": ["boredom", "confusion", "engagement", "frustration"],
    "label_ranges": {
        "boredom": [0, 3],
        "confusion": [0, 3],
        "engagement": [0, 3],
        "frustration": [0, 3]
    },
    "input_size": [224, 224],
    "preprocessing": {
        "resize": 256,
        "center_crop": 224,
        "normalization": {
            "mean": [0.485, 0.456, 0.406],
            "std": [0.229, 0.224, 0.225]
        }
    },
    "framework": "onnx",
    "onnx_opset": 11,
    "dataset": "DAiSEE",
    "baseline_metrics": {
        "val_mae": 0.5665,
        "val_rmse": 0.7016,
        "val_r2": -0.0014,
        "boredom_accuracy": 0.39,
        "confusion_accuracy": 0.46,
        "engagement_accuracy": 0.54,
        "frustration_accuracy": 0.72
    },
    "version": "1.0.0",
    "created_by": "Terorra",
    "license": "apache-2.0"
}

# Sauvegarde temporaire
config_path = "/tmp/config.json"
with open(config_path, "w") as f:
    json.dump(config, f, indent=2)

print("‚úÖ config.json cr√©√©\n")

# ============================================================================
# 4. CR√âER LE README.md
# ============================================================================

print("üìÑ Cr√©ation du README.md...")

readme_content = f"""---
license: apache-2.0
tags:
- emotion-detection
- tdah
- adhd
- computer-vision
- multi-label-regression
library_name: onnxruntime
pipeline_tag: image-classification
---

# üß† Wakee Emotion Detector

**Mod√®le de d√©tection d'√©motions pour accompagnement TDAH**

## üìä Description

Mod√®le EfficientNet B4 fine-tun√© sur le dataset DAiSEE pour d√©tecter 4 √©tats √©motionnels simultan√©s :

- **Boredom** (Ennui) : 0-3
- **Confusion** : 0-3  
- **Engagement** (Concentration) : 0-3
- **Frustration** : 0-3

Ce mod√®le est con√ßu pour l'application **Wakee** (Work Assistant with Kindness & Emotional Empathy), 
destin√©e √† aider les personnes atteintes de TDAH pendant leurs sessions de travail.

## üéØ Usage

### Avec ONNX Runtime (recommand√© pour production)
```python
import onnxruntime as ort
import numpy as np
from PIL import Image
from torchvision import transforms

# Load model
session = ort.InferenceSession("model.onnx")

# Preprocessing
transform = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

# Inference
image = Image.open("face.jpg").convert("RGB")
input_tensor = transform(image).unsqueeze(0).numpy()
outputs = session.run(['output'], {{'input': input_tensor}})
scores = outputs[0][0]  # [boredom, confusion, engagement, frustration]

print(f"Boredom: {{scores[0]:.2f}}/3")
print(f"Confusion: {{scores[1]:.2f}}/3")
print(f"Engagement: {{scores[2]:.2f}}/3")
print(f"Frustration: {{scores[3]:.2f}}/3")
```

### Avec HuggingFace Hub
```python
from huggingface_hub import hf_hub_download

model_path = hf_hub_download(
    repo_id="{REPO_ID}",
    filename="model.onnx"
)
# Ensuite utilise model_path avec onnxruntime
```

## üìà Performances (Baseline)

| M√©trique | Valeur |
|----------|--------|
| **MAE globale** | 0.57 |
| **RMSE** | 0.70 |
| Boredom Accuracy | 39% |
| Confusion Accuracy | 46% |
| Engagement Accuracy | 54% |
| Frustration Accuracy | **72%** ‚úÖ |

## üèóÔ∏è Architecture

- **Base model** : EfficientNet B4 (pr√©-entra√Æn√© sur ImageNet)
- **Fine-tuning** : DAiSEE dataset
- **Output** : 4 scores de r√©gression (0-3)
- **Loss** : Smooth L1 Loss
- **Framework** : PyTorch ‚Üí ONNX export

## üì¶ Dataset

Entra√Æn√© sur **DAiSEE** (Dataset for Affective States in E-Environments) :
- 9,068 vid√©os
- 112 sujets
- 4 labels : Boredom, Engagement, Confusion, Frustration
- √âchelle 0-3 pour chaque label

## üîÑ MLOps Pipeline

Ce mod√®le fait partie d'un pipeline MLOps complet :

1. **Collecte continue** : Images d'utilisateurs r√©els via app de sourcing
2. **Drift detection** : Evidently AI (hebdomadaire)
3. **R√©entra√Ænement automatique** : Airflow orchestration
4. **Versioning** : MLflow model registry

## üë®‚Äçüíª Auteur

D√©velopp√© par **Terorra** dans le cadre du projet Wakee (certification AIA Lead).

## üìÑ License

Apache 2.0

## üîó Liens

- [Wakee App Repository](https://github.com/{HF_USERNAME}/wakee-reloaded)
- [API Endpoint](https://huggingface.co/spaces/{HF_USERNAME}/wakee-api)
- [Annotation App](https://huggingface.co/spaces/{HF_USERNAME}/wakee-sourcing)
"""

readme_path = "/tmp/README.md"
with open(readme_path, "w", encoding="utf-8") as f:
    f.write(readme_content)

print("‚úÖ README.md cr√©√©\n")

# ============================================================================
# 5. UPLOAD VERS HUGGINGFACE HUB
# ============================================================================

print("üöÄ Upload des fichiers vers HuggingFace Hub...\n")

# 5.1 Upload ONNX model
print("üì§ Upload du mod√®le ONNX...")
if not Path(ONNX_MODEL_PATH).exists():
    print(f"‚ùå ERREUR : Fichier introuvable : {ONNX_MODEL_PATH}")
    print("üëâ V√©rifie le chemin vers ton daisee_model.onnx")
    exit(1)

try:
    api.upload_file(
        path_or_fileobj=ONNX_MODEL_PATH,
        path_in_repo="model.onnx",
        repo_id=REPO_ID,
        repo_type="model",
        commit_message="Initial upload: ONNX model from DAiSEE training"
    )
    print("‚úÖ model.onnx upload√©\n")
except Exception as e:
    print(f"‚ùå Erreur upload ONNX : {e}\n")
    exit(1)

# 5.2 Upload config.json
print("üì§ Upload du config.json...")
try:
    api.upload_file(
        path_or_fileobj=config_path,
        path_in_repo="config.json",
        repo_id=REPO_ID,
        repo_type="model",
        commit_message="Add model configuration"
    )
    print("‚úÖ config.json upload√©\n")
except Exception as e:
    print(f"‚ùå Erreur upload config : {e}\n")

# 5.3 Upload README.md
print("üì§ Upload du README.md...")
try:
    api.upload_file(
        path_or_fileobj=readme_path,
        path_in_repo="README.md",
        repo_id=REPO_ID,
        repo_type="model",
        commit_message="Add comprehensive README"
    )
    print("‚úÖ README.md upload√©\n")
except Exception as e:
    print(f"‚ùå Erreur upload README : {e}\n")

# ============================================================================
# 6. V√âRIFICATION
# ============================================================================

print("=" * 70)
print("üéâ UPLOAD TERMIN√â !")
print("=" * 70)
print(f"\n‚úÖ Ton mod√®le est disponible sur :")
print(f"   üëâ https://huggingface.co/{REPO_ID}\n")

print("üîç V√©rifications √† faire :")
print("   1. Visite le lien ci-dessus")
print("   2. V√©rifie que model.onnx est bien l√† (devrait faire ~50-100 MB)")
print("   3. Lis le README g√©n√©r√©")
print("   4. Teste le download :\n")

print("=" * 70)
print("üìù CODE DE TEST (√† ex√©cuter s√©par√©ment) :")
print("=" * 70)

test_code = f"""
from huggingface_hub import hf_hub_download
import onnxruntime as ort

# Download
model_path = hf_hub_download(
    repo_id="{REPO_ID}",
    filename="model.onnx"
)

# Test load
session = ort.InferenceSession(model_path)
print(f"‚úÖ Mod√®le charg√© : {{model_path}}")
print(f"   Input : {{session.get_inputs()[0].name}}")
print(f"   Output : {{session.get_outputs()[0].name}}")
print(f"   Shape : {{session.get_inputs()[0].shape}}")
"""

print(test_code)
print("=" * 70)

# Cleanup
os.remove(config_path)
os.remove(readme_path)

print("\n‚úÖ Script termin√© ! Passe au script suivant : onnx_to_pytorch.py\n")