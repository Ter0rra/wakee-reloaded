# ğŸš€ Wakee Airflow - Pipeline MLOps

Pipeline d'orchestration MLOps pour le projet Wakee Reloaded.

## ğŸ“Š Architecture

```
Airflow Scheduler
    â”œâ”€â”€ DAG 1: health_check_weekly (Dimanche 3h)
    â”‚   â”œâ”€â”€ Test API
    â”‚   â”œâ”€â”€ Test Database
    â”‚   â”œâ”€â”€ Test Storage (R2)
    â”‚   â”œâ”€â”€ Test App Sourcing
    â”‚   â”œâ”€â”€ Test Model Hub
    â”‚   â”œâ”€â”€ Run Pytest suite
    â”‚   â””â”€â”€ Generate Summary
    â”‚
    â”œâ”€â”€ DAG 2: drift_detection_daily (Quotidien 2h)
    â”‚   â”œâ”€â”€ Fetch annotations from NeonDB
    â”‚   â”œâ”€â”€ Load predictions
    â”‚   â”œâ”€â”€ Calculate drift (Evidently AI)
    â”‚   â”œâ”€â”€ Generate drift report
    â”‚   â”œâ”€â”€ Save report to NeonDB
    â”‚   â””â”€â”€ Trigger retrain if drift > threshold
    â”‚
    â””â”€â”€ DAG 3: model_retrain (Manuel / Triggered)
        â”œâ”€â”€ Fetch training data (NeonDB + R2)
        â”œâ”€â”€ Split train/val/test
        â”œâ”€â”€ Fine-tune PyTorch model
        â”œâ”€â”€ Evaluate on test set
        â”œâ”€â”€ Export to ONNX
        â”œâ”€â”€ Upload to HF Model Hub
        â”œâ”€â”€ Log metrics to MLflow
        â””â”€â”€ Update model_versions table
```

## ğŸ› ï¸ Installation

### PrÃ©requis

- Docker & Docker Compose
- 4GB+ RAM disponible
- 10GB+ espace disque

### Setup

1. **Clone le repository**
```bash
cd wakee_reloaded/03_Airflow
```

2. **Configure les variables d'environnement**
```bash
cp .env.example .env
# Ã‰dite .env avec tes credentials
```

3. **DÃ©finis l'UID Airflow (Linux seulement)**
```bash
echo "AIRFLOW_UID=$(id -u)" >> .env
```

4. **Build l'image Docker**
```bash
docker-compose build
```

5. **Initialize Airflow**
```bash
docker-compose up airflow-init
```

6. **Lance Airflow**
```bash
docker-compose up -d
```

7. **AccÃ¨de Ã  l'interface Web**
```
URL: http://localhost:8080
Username: airflow
Password: airflow
```

## ğŸ“ Structure

```
03_Airflow/
â”œâ”€â”€ dags/
â”‚   â”œâ”€â”€ dag_health_check.py      # Health checks hebdomadaires
â”‚   â”œâ”€â”€ dag_drifting.py          # DÃ©tection drift quotidienne
â”‚   â””â”€â”€ dag_retrain.py           # RÃ©entraÃ®nement modÃ¨le
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_api_health.py
â”‚   â”œâ”€â”€ test_database.py
â”‚   â”œâ”€â”€ test_storage.py
â”‚   â””â”€â”€ test_model.py
â”‚
â”œâ”€â”€ docker-compose.yml           # Configuration services
â”œâ”€â”€ Dockerfile                   # Image Airflow custom
â”œâ”€â”€ requirements.txt             # DÃ©pendances Python
â”œâ”€â”€ .env.example                 # Template variables
â””â”€â”€ README.md                    # Ce fichier
```

## ğŸ”§ Configuration

### Variables d'environnement requises

```bash
# NeonDB
NEON_DATABASE_URL=postgresql://user:pass@host/db

# Cloudflare R2
R2_ACCOUNT_ID=your_account_id
R2_ACCESS_KEY_ID=your_access_key
R2_SECRET_ACCESS_KEY=your_secret_key
R2_BUCKET_NAME=wakee-bucket

# HuggingFace
HF_TOKEN=hf_xxxxx
```

## ğŸ“Š DAGs

### DAG 1: Health Check (Hebdomadaire)

**Schedule:** Dimanche 3h du matin

**Tests:**
- âœ… API endpoints (/health, /predict)
- âœ… Database (NeonDB connexion, tables)
- âœ… Storage (R2 upload/download)
- âœ… App Sourcing (accessibilitÃ©)
- âœ… Model Hub (download modÃ¨le)
- âœ… Pytest suite

**Output:** Rapport de santÃ© complet

### DAG 2: Drift Detection (Quotidien)

**Schedule:** Tous les jours Ã  2h

**Process:**
1. RÃ©cupÃ¨re annotations validÃ©es (NeonDB)
2. Compare avec prÃ©dictions initiales
3. Calcule mÃ©triques de drift (Evidently AI)
4. GÃ©nÃ¨re rapport de drift
5. Sauvegarde dans drift_reports table
6. DÃ©clenche rÃ©entraÃ®nement si drift > seuil

**Seuil de drift:** 0.15 (configurable)

### DAG 3: Model Retrain (Manuel/Triggered)

**Triggers:**
- Manuel (via UI Airflow)
- Automatique si drift dÃ©tectÃ©

**Process:**
1. Download donnÃ©es (R2 + NeonDB)
2. Preprocessing & split
3. Fine-tune EfficientNet B4
4. Ã‰valuation (accuracy, F1, confusion matrix)
5. Export ONNX
6. Upload HF Model Hub
7. Log MLflow
8. Update model_versions table

**DurÃ©e:** ~30-60 minutes

## ğŸ§ª Tests

### ExÃ©cuter les tests manuellement

```bash
docker-compose exec airflow-scheduler pytest /opt/airflow/tests -v
```

### Tests inclus

- `test_api_health.py`: Tests endpoints API
- `test_database.py`: Tests connexion/tables NeonDB
- `test_storage.py`: Tests upload/download R2
- `test_model.py`: Tests infÃ©rence ONNX

## ğŸ“ Logs

### AccÃ©der aux logs

```bash
# Logs Airflow webserver
docker-compose logs airflow-webserver

# Logs scheduler
docker-compose logs airflow-scheduler

# Logs spÃ©cifiques Ã  un DAG
# Via UI: http://localhost:8080 â†’ DAGs â†’ [Nom du DAG] â†’ Logs
```

### Emplacement des logs

```
03_Airflow/logs/
â”œâ”€â”€ dag_id=health_check_weekly/
â”œâ”€â”€ dag_id=drift_detection_daily/
â””â”€â”€ dag_id=model_retrain/
```

## ğŸ”„ Maintenance

### ArrÃªter Airflow

```bash
docker-compose down
```

### RedÃ©marrer Airflow

```bash
docker-compose restart
```

### Nettoyer les volumes

```bash
docker-compose down -v
```

### Rebuild aprÃ¨s changement requirements

```bash
docker-compose build --no-cache
docker-compose up -d
```

## ğŸ“Š Monitoring

### Interface Airflow

- **URL:** http://localhost:8080
- **DAGs:** Liste des pipelines
- **Graph View:** Visualisation du flow
- **Task Logs:** Logs dÃ©taillÃ©s de chaque tÃ¢che
- **XCom:** Variables partagÃ©es entre tÃ¢ches

### MÃ©triques

Airflow expose des mÃ©triques sur:
- DurÃ©e d'exÃ©cution des DAGs
- Taux de succÃ¨s/Ã©chec
- Temps d'attente des tÃ¢ches

## ğŸ› Troubleshooting

### Erreur: "Permission denied"

```bash
# Linux: DÃ©finis AIRFLOW_UID
echo "AIRFLOW_UID=$(id -u)" >> .env
docker-compose down
docker-compose up -d
```

### Erreur: "Database not found"

```bash
# RÃ©initialise la DB Airflow
docker-compose down -v
docker-compose up airflow-init
docker-compose up -d
```

### DAG ne s'affiche pas

```bash
# VÃ©rifie les erreurs de syntaxe
docker-compose exec airflow-scheduler python /opt/airflow/dags/dag_health_check.py

# RedÃ©marre le scheduler
docker-compose restart airflow-scheduler
```

### Variables d'environnement non chargÃ©es

```bash
# VÃ©rifie le .env
cat .env

# Rebuild avec nouvelles variables
docker-compose down
docker-compose up -d
```

## ğŸ“š Resources

- [Airflow Documentation](https://airflow.apache.org/docs/)
- [Docker Compose Guide](https://docs.docker.com/compose/)
- [Evidently AI Docs](https://docs.evidentlyai.com/)
- [MLflow Documentation](https://mlflow.org/docs/latest/index.html)

## ğŸ¯ Next Steps

1. âœ… Setup Airflow
2. â³ CrÃ©er DAG drift detection
3. â³ CrÃ©er DAG retrain
4. â³ IntÃ©grer MLflow
5. â³ Configurer alertes email

## ğŸ“§ Support

Pour toute question, ouvre une issue sur le repository GitHub.

---

**DÃ©veloppÃ© avec ğŸ’™ pour la certification AIA Lead MLOps**
